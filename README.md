# Colourise Video

**Colourise Video** is a tool for converting black-and-white videos into colored videos using deep learning techniques. This project provides a simple pipeline to take input videos in grayscale and output them in color, enhancing their visual appeal using AI.

## Features

- Convert black-and-white videos to color using a pre-trained deep learning model.
- Supports a variety of video formats.
- Easy-to-use Jupyter Notebook interface for processing.

## Getting Started

### Prerequisites

Before running the code, ensure you have the following installed:

- Python 3.8+
- Jupyter Notebook
- `ffmpeg` for video processing
- Required Python libraries (listed in `requirements.txt`)

### Installation

1. **Clone the repository:**
   ```bash
   git clone https://github.com/your-username/ColouriseVideo.git
   cd ColouriseVideo
   ```

2. **Install the required dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Ensure `ffmpeg` is installed** (required for video manipulation):
   - For Linux/macOS:
     ```bash
     sudo apt install ffmpeg
     ```
   - For Windows, follow [this guide](https://ffmpeg.org/download.html) to download and add `ffmpeg` to your PATH.

### Usage

1. **Launch the Jupyter Notebook:**
   ```bash
   jupyter notebook ColouriseVideo.ipynb
   ```

2. **Upload a black-and-white video file** in the cell designated for input. The model will process this video and output a colored version.

3. **Run the cells** as per the instructions in the notebook to convert the video.

4. **Download the colored video** generated by the model, which will be saved in the specified output folder.

### Example

Upload a video named `input_video.mp4` in grayscale and run the notebook. The resulting video `output_video.mp4` will appear in the `output/` directory, showcasing the colorized version of the original.

## How It Works

The tool uses a deep learning model to predict the color information of each frame in a grayscale video. It processes each frame and then reconstructs the video with the colorized frames using `ffmpeg`.

- **Model Architecture**: The core of the colorization process uses a pre-trained convolutional neural network (CNN) fine-tuned for colorizing images. The model predicts the color channels for each frame.
- **Video Reconstruction**: `ffmpeg` is used to reconstruct the frames into a video, ensuring the output maintains the same frame rate as the input.

## Folder Structure

```
ColouriseVideo/
│
├── ColouriseVideo.ipynb      # Main Jupyter Notebook for colorization
├── requirements.txt          # Python dependencies
├── input/                    # Folder to store input black-and-white videos
├── output/                   # Folder to save colorized videos
└── README.md                 # Project documentation
```

## Contributing

Contributions are welcome! Please follow these steps to contribute:

1. Fork the repository.
2. Create a new branch (`feature/your-feature`).
3. Commit your changes (`git commit -m 'Add your feature'`).
4. Push to the branch (`git push origin feature/your-feature`).
5. Open a pull request.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgements

- Pre-trained models for colorization were adapted from research in the field of computer vision.
- Special thanks to the open-source community for continuous improvements in video processing and machine learning.

## Contact

For questions or feedback, please reach out to [Deepanshu Tomar](https://instagram.com/deepanshutomarg).
