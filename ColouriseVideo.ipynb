{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwrivWDCUqRC",
        "outputId": "f7536600-aeb0-4e22-eff9-8ff3985ab65c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (10.4.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install pillow\n",
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arGWLPXA5Ulg",
        "outputId": "5812a162-7a61-4b04-ddca-96a3413481fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded colorization_deploy_v2.prototxt to model/colorization_deploy_v2.prototxt\n",
            "Downloaded pts_in_hull.npy to model/pts_in_hull.npy\n",
            "Downloaded colorization_release_v2.caffemodel to model/colorization_release_v2.caffemodel\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "# Create the 'models' directory if it doesn't exist\n",
        "if not os.path.exists('model'):\n",
        "    os.makedirs('model')\n",
        "\n",
        "# Download the model files\n",
        "model_files = [\n",
        "    ('colorization_deploy_v2.prototxt', 'https://raw.githubusercontent.com/richzhang/colorization/caffe/colorization/models/colorization_deploy_v2.prototxt'),\n",
        "    ('pts_in_hull.npy', 'https://raw.githubusercontent.com/richzhang/colorization/caffe/colorization/resources/pts_in_hull.npy'),\n",
        "    ('colorization_release_v2.caffemodel', 'https://www.dropbox.com/s/dx0qvhhp5hbcx7z/colorization_release_v2.caffemodel?dl=1')\n",
        "]\n",
        "\n",
        "for filename, url in model_files:\n",
        "    filepath = os.path.join('model', filename)\n",
        "    try:\n",
        "        urllib.request.urlretrieve(url, filepath)\n",
        "        print(f\"Downloaded {filename} to {filepath}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading {filename}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import ffmpeg\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load the colorization model\n",
        "prototxt_path = 'model/colorization_deploy_v2.prototxt'\n",
        "model_path = 'model/colorization_release_v2.caffemodel'\n",
        "cluster_centers_path = 'model/pts_in_hull.npy'\n",
        "\n",
        "net = cv2.dnn.readNetFromCaffe(prototxt_path, model_path)\n",
        "pts_in_hull = np.load(cluster_centers_path)\n",
        "pts_in_hull = pts_in_hull.transpose().reshape(2, 313, 1, 1).astype(np.float32)\n",
        "class8 = net.getLayerId('class8_ab')\n",
        "conv8 = net.getLayerId('conv8_313_rh')\n",
        "net.getLayer(class8).blobs = [pts_in_hull]\n",
        "net.getLayer(conv8).blobs = [np.full([1, 313], 2.606, dtype=\"float32\")]"
      ],
      "metadata": {
        "id": "pQ1y8AWmG00V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to colorize a frame\n",
        "def colorize_frame(frame):\n",
        "    print(\"Colorizing frame...\")\n",
        "    scaled = frame.astype(\"float32\") / 255.0\n",
        "    lab = cv2.cvtColor(scaled, cv2.COLOR_BGR2LAB)\n",
        "    L = lab[:, :, 0]\n",
        "    L_resized = cv2.resize(L, (224, 224))\n",
        "    L_resized -= 50\n",
        "    net.setInput(cv2.dnn.blobFromImage(L_resized))\n",
        "    ab = net.forward()[0, :, :, :].transpose((1, 2, 0))\n",
        "    ab_resized = cv2.resize(ab, (frame.shape[1], frame.shape[0]))\n",
        "    L = lab[:, :, 0]\n",
        "    colorized = np.concatenate((L[:, :, np.newaxis], ab_resized), axis=2)\n",
        "    colorized = cv2.cvtColor(colorized, cv2.COLOR_LAB2BGR)\n",
        "    colorized = (colorized * 255).astype(\"uint8\")\n",
        "    return colorized\n"
      ],
      "metadata": {
        "id": "5w5kATOzG36y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Upload a video\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "input_video_path = list(uploaded.keys())[0]  # Get the uploaded file name\n",
        "\n",
        "# Step 2: Separate audio from video\n",
        "def extract_audio(input_video, output_audio):\n",
        "    ffmpeg.input(input_video).output(output_audio).run()\n",
        "\n",
        "audio_path = 'output_audio.aac'\n",
        "extract_audio(input_video_path, audio_path)\n",
        "\n",
        "# Step 3: Convert video into frames\n",
        "def video_to_frames(video_path, output_folder):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    count = 0\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        cv2.imwrite(f\"{output_folder}/frame_{count:05d}.jpg\", frame)\n",
        "        count += 1\n",
        "    cap.release()\n",
        "\n",
        "frame_folder = 'frames'\n",
        "video_to_frames(input_video_path, frame_folder)\n",
        "\n",
        "# Step 4: Apply colorization to each frame\n",
        "def colorize_frames(input_folder, output_folder):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    frame_files = sorted(os.listdir(input_folder))\n",
        "    for frame_file in frame_files:\n",
        "        frame_path = os.path.join(input_folder, frame_file)\n",
        "        frame = cv2.imread(frame_path)\n",
        "        colorized_frame = colorize_frame(frame)\n",
        "        output_frame_path = os.path.join(output_folder, frame_file)\n",
        "        cv2.imwrite(output_frame_path, colorized_frame)\n",
        "\n",
        "colorized_frame_folder = 'colorized_frames'\n",
        "colorize_frames(frame_folder, colorized_frame_folder)\n",
        "\n",
        "# Step 5: Reconstruct the video from the colorized frames\n",
        "def frames_to_video(frame_folder, output_video_path, fps):\n",
        "    frame_files = sorted([os.path.join(frame_folder, img) for img in os.listdir(frame_folder)])\n",
        "    frame = cv2.imread(frame_files[0])\n",
        "    height, width, layers = frame.shape\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "    for frame_file in frame_files:\n",
        "        frame = cv2.imread(frame_file)\n",
        "        out.write(frame)\n",
        "    out.release()\n",
        "\n",
        "output_video_path = 'colorized_video.mp4'\n",
        "frames_to_video(colorized_frame_folder, output_video_path, fps=24)\n",
        "\n",
        "# Step 6: Add audio to the video\n",
        "def add_audio_to_video(video_path, audio_path, output_path):\n",
        "    input_video = ffmpeg.input(video_path)\n",
        "    input_audio = ffmpeg.input(audio_path)\n",
        "    ffmpeg.output(input_video, input_audio, output_path).run()\n"
      ],
      "metadata": {
        "id": "p6NRKJSJG795"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_video_path = 'final_video_with_audio.mp4'\n",
        "add_audio_to_video(output_video_path, audio_path, final_video_path)\n",
        "\n",
        "print(f\"Video saved at {final_video_path}\")"
      ],
      "metadata": {
        "id": "2PWq5EjCG_SR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}